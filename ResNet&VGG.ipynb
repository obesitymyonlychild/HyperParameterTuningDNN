{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyzOT64xkqy6"
      },
      "source": [
        "# CSC413/2516 Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjPTaRB4mpCd"
      },
      "source": [
        "# Hyperparameter Sensitivity Analysis for Adam Optimization on Deep CNNs\n",
        "\n",
        "Abhishek Madan and Fei Wu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9IS9B9-yUU5"
      },
      "source": [
        "# Code Overview\n",
        "The code from this notebook is adapted from the notebook used for PA2, though with several modifications. Aside from the different networks implemented for this project, the training loop and model evaluation code now return a per-image classification distribution instead of a per-pixel classification distribution.\n",
        "\n",
        "Since we ran all of our experiments in the free tier of Colab, the experiments were run one at a time, changing hyperparameters and re-running for each experiment, with the relevant results pickled and downloaded after each run. The pickle files were loaded and plotted offline, though no training or other analysis was done offline. As such, the plotting code is not included in the submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BIpGwANoQOg"
      },
      "source": [
        "#### Helper code\n",
        "You can ignore the restart warning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piDmAsqFG0gU",
        "outputId": "5b44b595-910b-414c-d6f0-70e1162b4e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/csc413/a2\n"
          ]
        }
      ],
      "source": [
        "######################################################################\n",
        "# Setup working directory\n",
        "######################################################################\n",
        "%mkdir -p /content/csc413/a2/\n",
        "%cd /content/csc413/a2\n",
        "\n",
        "######################################################################\n",
        "# Helper functions for loading data\n",
        "######################################################################\n",
        "# adapted from\n",
        "# https://github.com/fchollet/keras/blob/master/keras/datasets/cifar10.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import sys\n",
        "import tarfile\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "\n",
        "\n",
        "def get_file(fname, origin, untar=False, extract=False, archive_format=\"auto\", cache_dir=\"data\"):\n",
        "    datadir = os.path.join(cache_dir)\n",
        "    if not os.path.exists(datadir):\n",
        "        os.makedirs(datadir)\n",
        "\n",
        "    if untar:\n",
        "        untar_fpath = os.path.join(datadir, fname)\n",
        "        fpath = untar_fpath + \".tar.gz\"\n",
        "    else:\n",
        "        fpath = os.path.join(datadir, fname)\n",
        "\n",
        "    print(\"File path: %s\" % fpath)\n",
        "    if not os.path.exists(fpath):\n",
        "        print(\"Downloading data from\", origin)\n",
        "\n",
        "        error_msg = \"URL fetch failure on {}: {} -- {}\"\n",
        "        try:\n",
        "            try:\n",
        "                urlretrieve(origin, fpath)\n",
        "            except URLError as e:\n",
        "                raise Exception(error_msg.format(origin, e.errno, e.reason))\n",
        "            except HTTPError as e:\n",
        "                raise Exception(error_msg.format(origin, e.code, e.msg))\n",
        "        except (Exception, KeyboardInterrupt) as e:\n",
        "            if os.path.exists(fpath):\n",
        "                os.remove(fpath)\n",
        "            raise\n",
        "\n",
        "    if untar:\n",
        "        if not os.path.exists(untar_fpath):\n",
        "            print(\"Extracting file.\")\n",
        "            with tarfile.open(fpath) as archive:\n",
        "                archive.extractall(datadir)\n",
        "        return untar_fpath\n",
        "\n",
        "    if extract:\n",
        "        _extract_archive(fpath, datadir, archive_format)\n",
        "\n",
        "    return fpath\n",
        "\n",
        "\n",
        "def load_batch(fpath, label_key=\"labels\"):\n",
        "    \"\"\"Internal utility for parsing CIFAR data.\n",
        "    # Arguments\n",
        "        fpath: path the file to parse.\n",
        "        label_key: key for label data in the retrieve\n",
        "            dictionary.\n",
        "    # Returns\n",
        "        A tuple `(data, labels)`.\n",
        "    \"\"\"\n",
        "    f = open(fpath, \"rb\")\n",
        "    if sys.version_info < (3,):\n",
        "        d = pickle.load(f)\n",
        "    else:\n",
        "        d = pickle.load(f, encoding=\"bytes\")\n",
        "        # decode utf8\n",
        "        d_decoded = {}\n",
        "        for k, v in d.items():\n",
        "            d_decoded[k.decode(\"utf8\")] = v\n",
        "        d = d_decoded\n",
        "    f.close()\n",
        "    data = d[\"data\"]\n",
        "    labels = d[label_key]\n",
        "\n",
        "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "def load_cifar10(transpose=False):\n",
        "    \"\"\"Loads CIFAR10 dataset.\n",
        "    # Returns\n",
        "        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
        "    \"\"\"\n",
        "    dirname = \"cifar-10-batches-py\"\n",
        "    origin = \"http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
        "    path = get_file(dirname, origin=origin, untar=True)\n",
        "\n",
        "    num_train_samples = 50000\n",
        "\n",
        "    x_train = np.zeros((num_train_samples, 3, 32, 32), dtype=\"uint8\")\n",
        "    y_train = np.zeros((num_train_samples,), dtype=\"uint8\")\n",
        "\n",
        "    for i in range(1, 6):\n",
        "        fpath = os.path.join(path, \"data_batch_\" + str(i))\n",
        "        data, labels = load_batch(fpath)\n",
        "        x_train[(i - 1) * 10000 : i * 10000, :, :, :] = data\n",
        "        y_train[(i - 1) * 10000 : i * 10000] = labels\n",
        "\n",
        "    fpath = os.path.join(path, \"test_batch\")\n",
        "    x_test, y_test = load_batch(fpath)\n",
        "\n",
        "    y_train = np.reshape(y_train, (len(y_train), 1))\n",
        "    y_test = np.reshape(y_test, (len(y_test), 1))\n",
        "\n",
        "    if transpose:\n",
        "        x_train = x_train.transpose(0, 2, 3, 1)\n",
        "        x_test = x_test.transpose(0, 2, 3, 1)\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jIKvJNtoVgU"
      },
      "source": [
        "#### Download files\n",
        "\n",
        "This may take 1 or 2 mins for the first time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7fti3cryStt",
        "outputId": "736a450d-8330-4cab-ea0c-68fd6c187428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File path: data/colours.tar.gz\n",
            "Downloading data from http://www.cs.toronto.edu/~jba/kmeans_colour_a2.tar.gz\n",
            "Extracting file.\n",
            "File path: data/cifar-10-batches-py.tar.gz\n",
            "Downloading data from http://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Extracting file.\n"
          ]
        }
      ],
      "source": [
        "# Download cluster centers for k-means over colours\n",
        "colours_fpath = get_file(\n",
        "    fname=\"colours\", origin=\"http://www.cs.toronto.edu/~jba/kmeans_colour_a2.tar.gz\", untar=True\n",
        ")\n",
        "# Download CIFAR dataset\n",
        "m = load_cifar10()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWyZwl9VKkxD"
      },
      "source": [
        "## Helper code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTF1TQObE6DG"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Colourization of CIFAR-10 Horses via classification.\n",
        "\"\"\"\n",
        "import argparse\n",
        "import math\n",
        "import time\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import numpy.random as npr\n",
        "import scipy.misc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# from load_data import load_cifar10\n",
        "\n",
        "HORSE_CATEGORY = 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zN3FF8hIlS7h"
      },
      "source": [
        "#### Data related code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-900ROTMlSPd"
      },
      "outputs": [],
      "source": [
        "def get_rgb_cat(xs, colours):\n",
        "    \"\"\"\n",
        "    Get colour categories given RGB values. This function doesn't\n",
        "    actually do the work, instead it splits the work into smaller\n",
        "    chunks that can fit into memory, and calls helper function\n",
        "    _get_rgb_cat\n",
        "\n",
        "    Args:\n",
        "      xs: float numpy array of RGB images in [B, C, H, W] format\n",
        "      colours: numpy array of colour categories and their RGB values\n",
        "    Returns:\n",
        "      result: int numpy array of shape [B, 1, H, W]\n",
        "    \"\"\"\n",
        "    if np.shape(xs)[0] < 100:\n",
        "        return _get_rgb_cat(xs)\n",
        "    batch_size = 100\n",
        "    nexts = []\n",
        "    for i in range(0, np.shape(xs)[0], batch_size):\n",
        "        next = _get_rgb_cat(xs[i : i + batch_size, :, :, :], colours)\n",
        "        nexts.append(next)\n",
        "    result = np.concatenate(nexts, axis=0)\n",
        "    return result\n",
        "\n",
        "\n",
        "def _get_rgb_cat(xs, colours):\n",
        "    \"\"\"\n",
        "    Get colour categories given RGB values. This is done by choosing\n",
        "    the colour in `colours` that is the closest (in RGB space) to\n",
        "    each point in the image `xs`. This function is a little memory\n",
        "    intensive, and so the size of `xs` should not be too large.\n",
        "\n",
        "    Args:\n",
        "      xs: float numpy array of RGB images in [B, C, H, W] format\n",
        "      colours: numpy array of colour categories and their RGB values\n",
        "    Returns:\n",
        "      result: int numpy array of shape [B, 1, H, W]\n",
        "    \"\"\"\n",
        "    num_colours = np.shape(colours)[0]\n",
        "    xs = np.expand_dims(xs, 0)\n",
        "    cs = np.reshape(colours, [num_colours, 1, 3, 1, 1])\n",
        "    dists = np.linalg.norm(xs - cs, axis=2)  # 2 = colour axis\n",
        "    cat = np.argmin(dists, axis=0)\n",
        "    cat = np.expand_dims(cat, axis=1)\n",
        "    return cat\n",
        "\n",
        "\n",
        "def get_cat_rgb(cats, colours):\n",
        "    \"\"\"\n",
        "    Get RGB colours given the colour categories\n",
        "\n",
        "    Args:\n",
        "      cats: integer numpy array of colour categories\n",
        "      colours: numpy array of colour categories and their RGB values\n",
        "    Returns:\n",
        "      numpy tensor of RGB colours\n",
        "    \"\"\"\n",
        "    return colours[cats]\n",
        "\n",
        "\n",
        "def process(xs, ys, max_pixel=256.0, downsize_input=False):\n",
        "    \"\"\"\n",
        "    Pre-process CIFAR10 images by shuffling, subtracting the per-pixel mean,\n",
        "    and have colour values be bound between 0 and 1\n",
        "\n",
        "    Args:\n",
        "      xs: the colour RGB pixel values\n",
        "      ys: the category labels\n",
        "      max_pixel: maximum pixel value in the original data\n",
        "    Returns:\n",
        "      xs: value normalized and shuffled colour images\n",
        "      ys: shuffled category labels\n",
        "    \"\"\"\n",
        "    indices = npr.permutation(xs.shape[0])\n",
        "\n",
        "    xs = xs / max_pixel\n",
        "    pixel_avg = np.mean(xs, axis=0, keepdims=True)\n",
        "    xs = xs - pixel_avg\n",
        "\n",
        "    return xs[indices, :, :, :], ys[indices].reshape(-1)\n",
        "\n",
        "\n",
        "def get_batch(x, y, batch_size):\n",
        "    \"\"\"\n",
        "    Generated that yields batches of data\n",
        "\n",
        "    Args:\n",
        "      x: input values\n",
        "      y: output labels\n",
        "      batch_size: size of each batch\n",
        "    Yields:\n",
        "      batch_x: a batch of inputs of size at most batch_size\n",
        "      batch_y: a batch of outputs of size at most batch_size\n",
        "    \"\"\"\n",
        "    N = np.shape(x)[0]\n",
        "    assert N == np.shape(y)[0]\n",
        "    for i in range(0, N, batch_size):\n",
        "        batch_x = x[i : i + batch_size, :, :, :]\n",
        "        batch_y = y[i : i + batch_size]\n",
        "        yield (batch_x, batch_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft0qRJgWlK2q"
      },
      "source": [
        "#### Torch helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgMknlyhlJvi"
      },
      "outputs": [],
      "source": [
        "def get_torch_vars(xs, ys, gpu=False):\n",
        "    \"\"\"\n",
        "    Helper function to convert numpy arrays to pytorch tensors.\n",
        "    If GPU is used, move the tensors to GPU.\n",
        "\n",
        "    Args:\n",
        "      xs (float numpy tenosor): greyscale input\n",
        "      ys (int numpy tenosor): categorical labels\n",
        "      gpu (bool): whether to move pytorch tensor to GPU\n",
        "    Returns:\n",
        "      Variable(xs), Variable(ys)\n",
        "    \"\"\"\n",
        "    xs = torch.from_numpy(xs).float()\n",
        "    ys = torch.from_numpy(ys).long()\n",
        "    if gpu:\n",
        "        xs = xs.cuda()\n",
        "        ys = ys.cuda()\n",
        "    return Variable(xs), Variable(ys)\n",
        "\n",
        "\n",
        "def compute_loss(criterion, outputs, labels, batch_size, num_classes):\n",
        "    \"\"\"\n",
        "    Helper function to compute the loss. Since this is a pixelwise\n",
        "    prediction task we need to reshape the output and ground truth\n",
        "    tensors into a 2D tensor before passing it in to the loss criteron.\n",
        "\n",
        "    Args:\n",
        "      criterion: pytorch loss criterion\n",
        "      outputs (pytorch tensor): predicted labels from the model\n",
        "      labels (pytorch tensor): ground truth labels\n",
        "      batch_size (int): batch size used for training\n",
        "      num_classes (int): number of image categories\n",
        "    Returns:\n",
        "      pytorch tensor for loss\n",
        "    \"\"\"\n",
        "    return criterion(outputs, labels)\n",
        "\n",
        "\n",
        "def run_validation_step(\n",
        "    cnn,\n",
        "    criterion,\n",
        "    x_test_proc,\n",
        "    y_test_proc,\n",
        "    batch_size,\n",
        "    num_classes,\n",
        "    plotpath=None,\n",
        "    visualize=True,\n",
        "    downsize_input=False\n",
        "):\n",
        "    correct = 0.0\n",
        "    total = 0.0\n",
        "    losses = []\n",
        "    for i, (xs, ys) in enumerate(get_batch(x_test_proc, y_test_proc, batch_size)):\n",
        "        images, labels = get_torch_vars(xs, ys, args.gpu)\n",
        "        outputs = cnn(images)\n",
        "\n",
        "        val_loss = compute_loss(\n",
        "            criterion, outputs, labels, batch_size=args.batch_size, num_classes=num_classes\n",
        "        )\n",
        "        losses.append(val_loss.data.item())\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.data).sum()\n",
        "\n",
        "    val_loss = np.mean(losses)\n",
        "    val_acc = 100 * correct / total\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp_wCpMjqt5w"
      },
      "source": [
        "#### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syg8NjwMqw_F"
      },
      "outputs": [],
      "source": [
        "def plot(input, gtlabel, output, colours, path, visualize, compare_bilinear=False):\n",
        "    \"\"\"\n",
        "    Generate png plots of input, ground truth, and outputs\n",
        "\n",
        "    Args:\n",
        "      input: the greyscale input to the colourization CNN\n",
        "      gtlabel: the grouth truth categories for each pixel\n",
        "      output: the predicted categories for each pixel\n",
        "      colours: numpy array of colour categories and their RGB values\n",
        "      path: output path\n",
        "      visualize: display the figures inline or save the figures in path\n",
        "    \"\"\"\n",
        "    grey = np.transpose(input[:10, :, :, :], [0, 2, 3, 1])\n",
        "    gtcolor = get_cat_rgb(gtlabel[:10, 0, :, :], colours)\n",
        "    predcolor = get_cat_rgb(output[:10, 0, :, :], colours)\n",
        "\n",
        "    img_stack = [np.hstack(np.tile(grey, [1, 1, 1, 3])), np.hstack(gtcolor), np.hstack(predcolor)]\n",
        "\n",
        "    if compare_bilinear:\n",
        "        downsize_module = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Upsample(scale_factor=2, mode=\"bilinear\"),\n",
        "            nn.Upsample(scale_factor=2, mode=\"bilinear\"),\n",
        "        )\n",
        "        gt_input = np.transpose(\n",
        "            gtcolor,\n",
        "            [\n",
        "                0,\n",
        "                3,\n",
        "                1,\n",
        "                2\n",
        "            ],\n",
        "        )\n",
        "        color_bilinear = downsize_module.forward(torch.from_numpy(gt_input).float())\n",
        "        color_bilinear = np.transpose(color_bilinear.data.numpy(), [0, 2, 3, 1])\n",
        "        img_stack = [\n",
        "            np.hstack(np.transpose(input[:10, :, :, :], [0, 2, 3, 1])),\n",
        "            np.hstack(gtcolor),\n",
        "            np.hstack(predcolor),\n",
        "            np.hstack(color_bilinear),\n",
        "        ]\n",
        "    img = np.vstack(img_stack)\n",
        "\n",
        "    plt.grid(None)\n",
        "    plt.imshow(img, vmin=0.0, vmax=1.0)\n",
        "    if visualize:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(path)\n",
        "\n",
        "\n",
        "def toimage(img, cmin, cmax):\n",
        "    return Image.fromarray((img.clip(cmin, cmax) * 255).astype(np.uint8))\n",
        "\n",
        "\n",
        "def plot_activation(args, cnn):\n",
        "    # LOAD THE COLOURS CATEGORIES\n",
        "    colours = np.load(args.colours, allow_pickle=True)[0]\n",
        "    num_colours = np.shape(colours)[0]\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
        "    test_rgb, test_grey = process(x_test, y_test, downsize_input=args.downsize_input)\n",
        "    test_rgb_cat = get_rgb_cat(test_rgb, colours)\n",
        "\n",
        "    # Take the idnex of the test image\n",
        "    id = args.index\n",
        "    outdir = \"outputs/\" + args.experiment_name + \"/act\" + str(id)\n",
        "    if not os.path.exists(outdir):\n",
        "        os.makedirs(outdir)\n",
        "    images, labels = get_torch_vars(\n",
        "        np.expand_dims(test_grey[id], 0), np.expand_dims(test_rgb_cat[id], 0)\n",
        "    )\n",
        "    cnn.cpu()\n",
        "    outputs = cnn(images)\n",
        "    _, predicted = torch.max(outputs.data, 1, keepdim=True)\n",
        "    predcolor = get_cat_rgb(predicted.cpu().numpy()[0, 0, :, :], colours)\n",
        "    img = predcolor\n",
        "    toimage(predcolor, cmin=0, cmax=1).save(os.path.join(outdir, \"output_%d.png\" % id))\n",
        "\n",
        "    if not args.downsize_input:\n",
        "        img = np.tile(np.transpose(test_grey[id], [1, 2, 0]), [1, 1, 3])\n",
        "    else:\n",
        "        img = np.transpose(test_grey[id], [1, 2, 0])\n",
        "    toimage(img, cmin=0, cmax=1).save(os.path.join(outdir, \"input_%d.png\" % id))\n",
        "\n",
        "    img = np.transpose(test_rgb[id], [1, 2, 0])\n",
        "    toimage(img, cmin=0, cmax=1).save(os.path.join(outdir, \"input_%d_gt.png\" % id))\n",
        "\n",
        "    def add_border(img):\n",
        "        return np.pad(img, 1, \"constant\", constant_values=1.0)\n",
        "\n",
        "    def draw_activations(path, activation, imgwidth=4):\n",
        "        img = np.vstack(\n",
        "            [\n",
        "                np.hstack(\n",
        "                    [\n",
        "                        add_border(filter)\n",
        "                        for filter in activation[i * imgwidth : (i + 1) * imgwidth, :, :]\n",
        "                    ]\n",
        "                )\n",
        "                for i in range(activation.shape[0] // imgwidth)\n",
        "            ]\n",
        "        )\n",
        "        scipy.misc.imsave(path, img)\n",
        "\n",
        "    for i, tensor in enumerate([cnn.out1, cnn.out2, cnn.out3, cnn.out4, cnn.out5]):\n",
        "        draw_activations(\n",
        "            os.path.join(outdir, \"conv%d_out_%d.png\" % (i + 1, id)), tensor.data.cpu().numpy()[0]\n",
        "        )\n",
        "    print(\"visualization results are saved to %s\" % outdir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIa_fiZYnRy7"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtAdbbzHnP-n"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "\n",
        "\n",
        "def train(args, cnn=None):\n",
        "    # Set the maximum number of threads to prevent crash in Teaching Labs\n",
        "    # TODO: necessary?\n",
        "    torch.set_num_threads(5)\n",
        "    # Numpy random seed\n",
        "    npr.seed(args.seed)\n",
        "\n",
        "    # Save directory\n",
        "    save_dir = \"outputs/\" + args.experiment_name\n",
        "\n",
        "    # INPUT CHANNEL\n",
        "    num_in_channels = 3\n",
        "    # Network size (parameterized by n)\n",
        "    N = 6\n",
        "    # Num classes (10 for CIFAR10)\n",
        "    num_classes = 10\n",
        "    # LOAD THE MODEL\n",
        "    if cnn is None:\n",
        "        Net = globals()[args.model]\n",
        "        cnn = Net(args.kernel, args.num_filters, num_classes, num_in_channels, N)\n",
        "\n",
        "    # LOSS FUNCTION\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(cnn.parameters(), lr=args.learn_rate, betas=(args.beta1, args.beta2), eps=args.epsilon)\n",
        "\n",
        "    # DATA\n",
        "    print(\"Loading data...\")\n",
        "    (x_train, y_train), (x_test, y_test) = load_cifar10()\n",
        "\n",
        "    print(\"Transforming data...\")\n",
        "    x_train_proc, y_train_proc = process(x_train, y_train, downsize_input=args.downsize_input)\n",
        "    x_test_proc, y_test_proc = process(x_test, y_test, downsize_input=args.downsize_input)\n",
        "\n",
        "    # Create the outputs folder if not created already\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    print(\"Beginning training ...\")\n",
        "    if args.gpu:\n",
        "        cnn.cuda()\n",
        "    start = time.time()\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    valid_accs = []\n",
        "    for epoch in range(args.epochs):\n",
        "        # Train the Model\n",
        "        cnn.train()  # Change model to 'train' mode\n",
        "        losses = []\n",
        "        for i, (xs, ys) in enumerate(get_batch(x_train_proc, y_train_proc, args.batch_size)):\n",
        "            images, labels = get_torch_vars(xs, ys, args.gpu)\n",
        "            # Forward + Backward + Optimize\n",
        "            optimizer.zero_grad()\n",
        "            outputs = cnn(images)\n",
        "\n",
        "            loss = compute_loss(\n",
        "                criterion, outputs, labels, batch_size=args.batch_size, num_classes=num_classes\n",
        "            )\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses.append(loss.data.item())\n",
        "\n",
        "        # plot training images\n",
        "        avg_loss = np.mean(losses)\n",
        "        train_losses.append(avg_loss)\n",
        "        time_elapsed = time.time() - start\n",
        "        print(\n",
        "            \"Epoch [%d/%d], Loss: %.4f, Time (s): %d\"\n",
        "            % (epoch + 1, args.epochs, avg_loss, time_elapsed)\n",
        "        )\n",
        "\n",
        "        # Evaluate the model\n",
        "        cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
        "        val_loss, val_acc = run_validation_step(\n",
        "            cnn,\n",
        "            criterion,\n",
        "            x_test_proc,\n",
        "            y_test_proc,\n",
        "            args.batch_size,\n",
        "            num_classes,\n",
        "            save_dir + \"/test_%d.png\" % epoch,\n",
        "            args.visualize,\n",
        "            args.downsize_input,\n",
        "        )\n",
        "\n",
        "        time_elapsed = time.time() - start\n",
        "        valid_losses.append(val_loss)\n",
        "        valid_accs.append(val_acc)\n",
        "        print(\n",
        "            \"Epoch [%d/%d], Val Loss: %.4f, Val Acc: %.1f%%, Time(s): %.2f\"\n",
        "            % (epoch + 1, args.epochs, val_loss, val_acc, time_elapsed)\n",
        "        )\n",
        "\n",
        "    # Plot training curve\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, \"ro-\", label=\"Train\")\n",
        "    plt.plot(valid_losses, \"go-\", label=\"Validation\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.savefig(save_dir + \"/training_curve.png\")\n",
        "\n",
        "    if args.checkpoint:\n",
        "        print(\"Saving model...\")\n",
        "        torch.save(cnn.state_dict(), args.checkpoint)\n",
        "    \n",
        "    config_data = {}\n",
        "    config_data['train_losses'] = [l.item() for l in train_losses]\n",
        "    config_data['valid_losses'] = [l.item() for l in valid_losses]\n",
        "    config_data['valid_accs'] = [a.item() for a in valid_accs]\n",
        "    config_outfile = save_dir + '/losses_{}_a{}_b{}_bb{}_e{}.pickle'.format(\n",
        "        args.model, args.learn_rate, args.beta1, args.beta2, args.epsilon\n",
        "    )\n",
        "    with open(config_outfile, 'wb') as f:\n",
        "      pickle.dump(config_data, f, pickle.HIGHEST_PROTOCOL)\n",
        "    files.download(config_outfile)\n",
        "\n",
        "    return cnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vicMmF4WGF6t"
      },
      "source": [
        "# VGGNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAqGXV0iK1G9"
      },
      "source": [
        "## Code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoM5Lv4y3ZPJ"
      },
      "outputs": [],
      "source": [
        "class VGGNet(nn.Module):\n",
        "    def __init__(self, kernel, num_filters, num_classes, num_in_channels, n):\n",
        "        super().__init__()\n",
        "\n",
        "        # Useful parameters\n",
        "        padding = kernel // 2\n",
        "\n",
        "        self.fconv = nn.Sequential(\n",
        "            nn.Conv2d(num_in_channels, num_filters, kernel, padding=padding),\n",
        "            nn.BatchNorm2d(num_filters),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        layers1 = []\n",
        "        layers2 = []\n",
        "        layers3 = []\n",
        "        for i in range(n-1):\n",
        "          layers1.append(nn.Sequential(\n",
        "              nn.Conv2d(num_filters, num_filters, kernel, padding=padding),\n",
        "              nn.BatchNorm2d(num_filters),\n",
        "              nn.ReLU()\n",
        "          ))\n",
        "          layers2.append(nn.Sequential(\n",
        "              nn.Conv2d(2*num_filters, 2*num_filters, kernel, padding=padding),\n",
        "              nn.BatchNorm2d(2*num_filters),\n",
        "              nn.ReLU()\n",
        "          ))\n",
        "          layers3.append(nn.Sequential(\n",
        "              nn.Conv2d(4*num_filters, 4*num_filters, kernel, padding=padding),\n",
        "              nn.BatchNorm2d(4*num_filters),\n",
        "              nn.ReLU()\n",
        "          ))\n",
        "\n",
        "        layers1.append(nn.Sequential(\n",
        "            nn.Conv2d(num_filters, 2*num_filters, kernel, padding=padding, stride=2),\n",
        "            nn.BatchNorm2d(2*num_filters),\n",
        "            nn.ReLU()\n",
        "        ))\n",
        "        layers2.append(nn.Sequential(\n",
        "            nn.Conv2d(2*num_filters, 4*num_filters, kernel, padding=padding, stride=2),\n",
        "            nn.BatchNorm2d(4*num_filters),\n",
        "            nn.ReLU()\n",
        "        ))\n",
        "        layers3.append(nn.Sequential(\n",
        "            nn.Conv2d(4*num_filters, 4*num_filters, kernel, padding=padding),\n",
        "            nn.BatchNorm2d(4*num_filters),\n",
        "            nn.ReLU()\n",
        "        ))\n",
        "\n",
        "        self.conv1 = nn.Sequential(*layers1)\n",
        "        self.conv2 = nn.Sequential(*layers2)\n",
        "        self.conv3 = nn.Sequential(*layers3)\n",
        "\n",
        "        self.avg = nn.AvgPool2d(8)\n",
        "        self.output = nn.Linear(4*num_filters, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fconv(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.avg(x).squeeze()\n",
        "        return self.output(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTZWiuxMjQTB"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7KtLv5c30kU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "outputId": "38afceb9-73c3-45bf-e3ef-c744be6716c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "File path: data/cifar-10-batches-py.tar.gz\n",
            "Transforming data...\n",
            "Beginning training ...\n",
            "Epoch [1/15], Loss: 1.5085, Time (s): 41\n",
            "Epoch [1/15], Val Loss: 1.3227, Val Acc: 51.2%, Time(s): 43.51\n",
            "Epoch [2/15], Loss: 1.0596, Time (s): 84\n",
            "Epoch [2/15], Val Loss: 1.0212, Val Acc: 64.2%, Time(s): 86.92\n",
            "Epoch [3/15], Loss: 0.8627, Time (s): 127\n",
            "Epoch [3/15], Val Loss: 0.9761, Val Acc: 65.9%, Time(s): 130.32\n",
            "Epoch [4/15], Loss: 0.7430, Time (s): 171\n",
            "Epoch [4/15], Val Loss: 0.8482, Val Acc: 70.7%, Time(s): 173.70\n",
            "Epoch [5/15], Loss: 0.6584, Time (s): 214\n",
            "Epoch [5/15], Val Loss: 0.7888, Val Acc: 73.3%, Time(s): 217.10\n",
            "Epoch [6/15], Loss: 0.5916, Time (s): 258\n",
            "Epoch [6/15], Val Loss: 0.7182, Val Acc: 76.1%, Time(s): 260.46\n",
            "Epoch [7/15], Loss: 0.5367, Time (s): 301\n",
            "Epoch [7/15], Val Loss: 0.7851, Val Acc: 74.4%, Time(s): 303.81\n",
            "Epoch [8/15], Loss: 0.4847, Time (s): 344\n",
            "Epoch [8/15], Val Loss: 0.8669, Val Acc: 72.6%, Time(s): 347.22\n",
            "Epoch [9/15], Loss: 0.4428, Time (s): 388\n",
            "Epoch [9/15], Val Loss: 0.9770, Val Acc: 71.3%, Time(s): 390.58\n",
            "Epoch [10/15], Loss: 0.4070, Time (s): 431\n",
            "Epoch [10/15], Val Loss: 0.9519, Val Acc: 73.0%, Time(s): 433.94\n",
            "Epoch [11/15], Loss: 0.3783, Time (s): 474\n",
            "Epoch [11/15], Val Loss: 0.9573, Val Acc: 73.3%, Time(s): 477.29\n",
            "Epoch [12/15], Loss: 0.3457, Time (s): 518\n",
            "Epoch [12/15], Val Loss: 0.9111, Val Acc: 74.3%, Time(s): 520.69\n",
            "Epoch [13/15], Loss: 0.3122, Time (s): 561\n",
            "Epoch [13/15], Val Loss: 0.9617, Val Acc: 73.6%, Time(s): 564.04\n",
            "Epoch [14/15], Loss: 0.2814, Time (s): 605\n",
            "Epoch [14/15], Val Loss: 1.0198, Val Acc: 73.4%, Time(s): 607.42\n",
            "Epoch [15/15], Loss: 0.2614, Time (s): 648\n",
            "Epoch [15/15], Val Loss: 1.0143, Val Acc: 73.4%, Time(s): 650.80\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_752ef6ba-d737-4a2c-bca0-6f8948453040\", \"losses_VGGNet_a0.001_b0.9_bb0.99999_e1e-08.pickle\", 476)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "    \"gpu\": True,\n",
        "    \"valid\": False,\n",
        "    \"checkpoint\": \"\",\n",
        "    \"colours\": \"./data/colours/colour_kmeans24_cat7.npy\",\n",
        "    \"model\": \"VGGNet\",\n",
        "    \"kernel\": 3,\n",
        "    \"num_filters\": 16,\n",
        "    'learn_rate':0.001,\n",
        "    'beta1':0.9,\n",
        "    'beta2':0.99999,\n",
        "    'epsilon':1e-8, \n",
        "    \"batch_size\": 100,\n",
        "    \"epochs\": 15,\n",
        "    \"seed\": 0,\n",
        "    \"plot\": False,\n",
        "    \"experiment_name\": \"adam_sensitivity\",\n",
        "    \"visualize\": False,\n",
        "    \"downsize_input\": False,\n",
        "}\n",
        "args.update(args_dict)\n",
        "cnn = train(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4UgVSNGGOAf"
      },
      "source": [
        "# ResNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwJu-9EoR0JZ"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, shortcut=None, stride=1):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.conv2 = nn.Sequential(\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "        nn.BatchNorm2d(out_channels)\n",
        "    )\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    self.shortcut = shortcut\n",
        "\n",
        "  def forward(self, x):\n",
        "        identity = x\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "\n",
        "        if self.shortcut is not None:\n",
        "            identity = self.shortcut(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "HRcxW4x_8pCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSRh5tFR5cmQ"
      },
      "outputs": [],
      "source": [
        "class ResNet34(nn.Module):\n",
        "    \"\"\"\n",
        "    A ResNet layer composed by `n` blocks stacked one after the other\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel, num_filters, num_classes, num_in_channels, n):\n",
        "        super().__init__()\n",
        "        self.layer0 = nn.Sequential(\n",
        "          nn.Conv2d(num_in_channels, num_filters, kernel_size=7, stride=2, padding=3,bias=False),\n",
        "          nn.BatchNorm2d(num_filters),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size=kernel, stride=2, padding=1)\n",
        "          \n",
        "        )\n",
        "\n",
        "        self.layer1 = self.make_layer(num_filters,num_filters*2, 4, stride=1) \n",
        "        self.layer2 = self.make_layer(num_filters*2,num_filters*4, 4,stride=2)\n",
        "        self.layer3 = self.make_layer(num_filters*4,num_filters*4,6,stride=2) \n",
        "        self.layer4 = self.make_layer(num_filters*4,num_filters*8,3,stride=2)\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(num_filters*8, num_classes)\n",
        "\n",
        "    def make_layer(self, in_channels, out_channels, num_blocks, stride=1):\n",
        "        layers = []\n",
        "\n",
        "        shortcut = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "        layers.append(ResidualBlock(in_channels, out_channels, shortcut, stride))\n",
        "        for i in range(num_blocks - 1):\n",
        "            layers.append(ResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)     \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL8vT5OMSY9A"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXLe3bb6SZIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "outputId": "77f2fe95-0306-40de-e74c-a80a27ff662c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "File path: data/cifar-10-batches-py.tar.gz\n",
            "Transforming data...\n",
            "Beginning training ...\n",
            "Epoch [1/15], Loss: 1.7978, Time (s): 32\n",
            "Epoch [1/15], Val Loss: 1.5223, Val Acc: 44.5%, Time(s): 34.43\n",
            "Epoch [2/15], Loss: 1.3975, Time (s): 66\n",
            "Epoch [2/15], Val Loss: 1.3784, Val Acc: 50.3%, Time(s): 68.76\n",
            "Epoch [3/15], Loss: 1.1332, Time (s): 101\n",
            "Epoch [3/15], Val Loss: 1.3610, Val Acc: 52.0%, Time(s): 102.88\n",
            "Epoch [4/15], Loss: 0.8766, Time (s): 135\n",
            "Epoch [4/15], Val Loss: 1.4234, Val Acc: 51.6%, Time(s): 137.13\n",
            "Epoch [5/15], Loss: 0.6335, Time (s): 169\n",
            "Epoch [5/15], Val Loss: 1.5497, Val Acc: 52.2%, Time(s): 171.30\n",
            "Epoch [6/15], Loss: 0.4500, Time (s): 203\n",
            "Epoch [6/15], Val Loss: 1.7069, Val Acc: 52.8%, Time(s): 205.49\n",
            "Epoch [7/15], Loss: 0.3647, Time (s): 237\n",
            "Epoch [7/15], Val Loss: 1.8760, Val Acc: 52.3%, Time(s): 239.71\n",
            "Epoch [8/15], Loss: 0.3042, Time (s): 272\n",
            "Epoch [8/15], Val Loss: 1.9224, Val Acc: 52.2%, Time(s): 273.92\n",
            "Epoch [9/15], Loss: 0.2666, Time (s): 306\n",
            "Epoch [9/15], Val Loss: 1.9535, Val Acc: 53.3%, Time(s): 308.15\n",
            "Epoch [10/15], Loss: 0.2020, Time (s): 340\n",
            "Epoch [10/15], Val Loss: 2.0712, Val Acc: 53.7%, Time(s): 342.32\n",
            "Epoch [11/15], Loss: 0.1664, Time (s): 374\n",
            "Epoch [11/15], Val Loss: 2.0929, Val Acc: 54.5%, Time(s): 376.47\n",
            "Epoch [12/15], Loss: 0.1282, Time (s): 408\n",
            "Epoch [12/15], Val Loss: 2.1335, Val Acc: 54.8%, Time(s): 410.63\n",
            "Epoch [13/15], Loss: 0.0999, Time (s): 442\n",
            "Epoch [13/15], Val Loss: 2.1726, Val Acc: 55.2%, Time(s): 444.82\n",
            "Epoch [14/15], Loss: 0.0747, Time (s): 477\n",
            "Epoch [14/15], Val Loss: 2.2324, Val Acc: 55.7%, Time(s): 478.96\n",
            "Epoch [15/15], Loss: 0.0597, Time (s): 511\n",
            "Epoch [15/15], Val Loss: 2.3136, Val Acc: 56.1%, Time(s): 513.13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_190d6da9-d150-4a8b-88e4-5962605ce950\", \"losses_ResNet34_a0.001_b0.9_bb0.999_e1.pickle\", 476)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "args = AttrDict()\n",
        "args_dict = {\n",
        "    \"gpu\": True,\n",
        "    \"valid\": False,\n",
        "    \"checkpoint\": \"\",\n",
        "    \"colours\": \"./data/colours/colour_kmeans24_cat7.npy\",\n",
        "    \"model\": \"ResNet34\",\n",
        "    \"kernel\": 3,\n",
        "    \"num_filters\": 64,\n",
        "    'learn_rate':0.001,\n",
        "    'beta1':0.9,\n",
        "    'beta2':0.999,\n",
        "    'epsilon':1e-8, \n",
        "    \"batch_size\": 100,\n",
        "    \"epochs\": 15,\n",
        "    \"seed\": 0,\n",
        "    \"plot\": False,\n",
        "    \"experiment_name\": \"adam_sensitivity\",\n",
        "    \"visualize\": False,\n",
        "    \"downsize_input\": False,\n",
        "}\n",
        "args.update(args_dict)\n",
        "cnn = train(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "qP829Qemp1JG",
        "outputId": "6274b066-31bd-4a8e-b050-673721b3c67c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 19 16:31:10 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CSC413/2516 Project",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}